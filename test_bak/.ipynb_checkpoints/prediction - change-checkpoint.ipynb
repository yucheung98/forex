{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "e:\\envs\\python36env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "e:\\envs\\python36env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "e:\\envs\\python36env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "e:\\envs\\python36env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "e:\\envs\\python36env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "e:\\envs\\python36env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn import preprocessing\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_csv = pd.read_csv('EURUSD_data_D1_change.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_csv.drop(['Unnamed: 0','close'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      change\n",
      "0      -5.90\n",
      "1       4.60\n",
      "2     -11.50\n",
      "3     -17.60\n",
      "4      -1.90\n",
      "...      ...\n",
      "6005    3.90\n",
      "6006    0.67\n",
      "6007   -3.26\n",
      "6008    4.09\n",
      "6009   -2.96\n",
      "\n",
      "[6010 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -5.9 ],\n",
       "       [  4.6 ],\n",
       "       [-11.5 ],\n",
       "       ...,\n",
       "       [ -3.26],\n",
       "       [  4.09],\n",
       "       [ -2.96]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# #Max-Min标准化\n",
    "# #建立MinMaxScaler对象\n",
    "# scaler = preprocessing.StandardScaler()\n",
    "# # 标准化处理\n",
    "\n",
    "# data = scaler.fit_transform(data_csv)\n",
    "data = np.array(data_csv)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n = 0\n",
    "# for i in range(data.shape[0]):\n",
    "#     if data[i,0]<0:\n",
    "#         n=n+1\n",
    "# print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12000, 1)\n"
     ]
    }
   ],
   "source": [
    "data_y = data[-6000:,:]\n",
    "print(data_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.8089 ]\n",
      " [0.8093 ]\n",
      " [0.8081 ]\n",
      " ...\n",
      " [1.0912 ]\n",
      " [1.09798]\n",
      " [1.09066]]\n",
      "(120000, 1)\n"
     ]
    }
   ],
   "source": [
    "data_x = []\n",
    "for r in range(6000):\n",
    "    for c in range(10):\n",
    "        item = []\n",
    "        item.append(data[r+c, 0])\n",
    "        data_x.append(item)\n",
    "data_x = np.array(data_x)\n",
    "print(data_x)\n",
    "print(data_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x=data_x.reshape(12000,10,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12000, 10, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.8089 ],\n",
       "        [0.8093 ],\n",
       "        [0.8081 ],\n",
       "        ...,\n",
       "        [0.8136 ],\n",
       "        [0.8119 ],\n",
       "        [0.8133 ]],\n",
       "\n",
       "       [[0.8093 ],\n",
       "        [0.8081 ],\n",
       "        [0.8092 ],\n",
       "        ...,\n",
       "        [0.8119 ],\n",
       "        [0.8133 ],\n",
       "        [0.8173 ]],\n",
       "\n",
       "       [[0.8081 ],\n",
       "        [0.8092 ],\n",
       "        [0.8106 ],\n",
       "        ...,\n",
       "        [0.8133 ],\n",
       "        [0.8173 ],\n",
       "        [0.8158 ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[1.10349],\n",
       "        [1.09616],\n",
       "        [1.08568],\n",
       "        ...,\n",
       "        [1.09285],\n",
       "        [1.09347],\n",
       "        [1.0912 ]],\n",
       "\n",
       "       [[1.09616],\n",
       "        [1.08568],\n",
       "        [1.08127],\n",
       "        ...,\n",
       "        [1.09347],\n",
       "        [1.0912 ],\n",
       "        [1.09798]],\n",
       "\n",
       "       [[1.08568],\n",
       "        [1.08127],\n",
       "        [1.0792 ],\n",
       "        ...,\n",
       "        [1.0912 ],\n",
       "        [1.09798],\n",
       "        [1.09066]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_y = data_y.reshape(12000,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x_train = data_x[:10000,:, :]\n",
    "data_y_train = data_y[:10000,0,:]\n",
    "\n",
    "data_x_test = data_x[-2000:,:, :]\n",
    "data_y_test = data_y[-2000:,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 10, 1)\n",
      "(10000, 1)\n",
      "(2000, 10, 1)\n",
      "(2000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(data_x_train.shape)\n",
    "print(data_y_train.shape)\n",
    "print(data_x_test.shape)\n",
    "print(data_y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#     model = Sequential()\n",
    " \n",
    "#     model.add(LSTM(input_dim=10,output_dim=128,return_sequences=True))\n",
    "#     model.add(Dropout(0.1))\n",
    " \n",
    "#     model.add(LSTM(128,return_sequences=False))\n",
    "#     model.add(Dropout(0.1))\n",
    " \n",
    "#     model.add(Dense(output_dim=1))\n",
    "#     model.add(Activation(\"linear\"))\n",
    " \n",
    "#     model.compile(loss=\"mse\", optimizer=\"rmsprop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "\n",
    "# model.add(LSTM(output_dim=128, \n",
    "#                 input_shape=(10, 1),\n",
    "#                 activation='relu',\n",
    "#                 return_sequences=True))\n",
    "# for i in range(6):\n",
    "#     model.add(LSTM(output_dim=128,\n",
    "#                     activation='tanh',\n",
    "#                     return_sequences=True))\n",
    "# #     model.add(Dropout(0.1))\n",
    "\n",
    "# model.add(LSTM(output_dim=1,\n",
    "#                activation='linear',\n",
    "#                return_sequences=False))\n",
    "\n",
    "# model.compile(loss='mse', optimizer='adam', metrics=[metrics.mse])\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(output_dim1, num_layer, output_dim2):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(LSTM(output_dim=output_dim1, \n",
    "                input_shape=(10, 1),\n",
    "                activation='relu',\n",
    "                return_sequences=True))\n",
    "    for i in range(num_layer):\n",
    "        model.add(LSTM(output_dim=output_dim2,\n",
    "                        activation='tanh',\n",
    "                        return_sequences=True))\n",
    "#     model.add(Dropout(0.1))\n",
    "    model.add(LSTM(output_dim=output_dim2,\n",
    "                        activation='tanh'))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(loss='mse', optimizer='adam', metrics=[metrics.mse])\n",
    "#     model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import RandomizedSearchCV\n",
    "# from skopt.space import Real, Categorical, Integer\n",
    "# from keras.wrappers.scikit_learn import KerasRegressor\n",
    "# from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #采用暴力搜索，所有参数进行组合，然后选择最好的参数\n",
    "# tuned_parameters=[{'output_dim1':Integer(28, 128),\n",
    "#                    'num_layer':Integer(3,12),\n",
    "#                    'output_dim2':Integer(28, 128)}]\n",
    "# # 'output_dim1':Integer(28, 128),\n",
    "# #             'num_layer':Integer(3,12),\n",
    "# #             'output_dim2':Integer(28, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_x, test_x, train_y, test_y = train_test_split(data_x, data_y, train_size=0.80, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model=KerasRegressor(build_fn=create_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #采用随机搜索，给参数一个范围，然后系统随机选择参数，进行检验，然后选择最好的\n",
    "# tuned_parameters={'output_dim1':[28, 64, 96, 128],\n",
    "#                    'num_layer':[4,5,6],\n",
    "#                    'output_dim2':[28, 64, 96, 128]}\n",
    "\n",
    "# lstm=RandomizedSearchCV(model,tuned_parameters,scoring='neg_mean_squared_error',n_iter=2)\n",
    " \n",
    "# lstm.fit(data_x_train,data_y_train)\n",
    "# print('best parameters:',lstm.best_estimator_)\n",
    "# # print(classification_report(test_y,clf.predict(test_x)))\n",
    "# # print(metrics.confusion_matrix(test_y,clf.predict(test_x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sklearn\n",
    "# sorted(sklearn.metrics.SCORERS.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# from skopt import BayesSearchCV\n",
    "# from skopt.space import Real, Categorical, Integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class FixedBayesSearchCV(BayesSearchCV):\n",
    "#     \"\"\"\n",
    "#     Dirty hack to avoid compatibility issues with sklearn 0.2 and skopt.\n",
    "#     Credit: https://www.kaggle.com/c/home-credit-default-risk/discussion/64004\n",
    "#     For context, on why the workaround see:\n",
    "#         - https://github.com/scikit-optimize/scikit-optimize/issues/718\n",
    "#         - https://github.com/scikit-optimize/scikit-optimize/issues/762\n",
    "#     \"\"\"\n",
    "#     def __init__(self, estimator, search_spaces, optimizer_kwargs=None,\n",
    "#                 n_iter=50, scoring=None, fit_params=None, n_jobs=1,\n",
    "#                 n_points=1, iid=True, refit=True, cv=None, verbose=0,\n",
    "#                 pre_dispatch='2*n_jobs', random_state=None,\n",
    "#                 error_score='raise', return_train_score=False):\n",
    "#         \"\"\"\n",
    "#         See: https://github.com/scikit-optimize/scikit-optimize/issues/762#issuecomment-493689266\n",
    "#         \"\"\"\n",
    " \n",
    "#         # Bug fix: Added this line\n",
    "#         self.fit_params = fit_params\n",
    " \n",
    "#         self.search_spaces = search_spaces\n",
    "#         self.n_iter = n_iter\n",
    "#         self.n_points = n_points\n",
    "#         self.random_state = random_state\n",
    "#         self.optimizer_kwargs = optimizer_kwargs\n",
    "#         self._check_search_space(self.search_spaces)\n",
    " \n",
    "#         # Removed the passing of fit_params to the parent class.\n",
    "#         super(BayesSearchCV, self).__init__(\n",
    "#                 estimator=estimator, scoring=scoring, n_jobs=n_jobs, iid=iid,\n",
    "#                 refit=refit, cv=cv, verbose=verbose, pre_dispatch=pre_dispatch,\n",
    "#                 error_score=error_score, return_train_score=return_train_score)\n",
    " \n",
    "#     def _run_search(self, x):\n",
    "#         raise BaseException('Use newer skopt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def lstm_auto_para_tuning_bayesian(model,data_x,data_y):\n",
    "#     train_x, test_x, train_y, test_y = train_test_split(data_x, data_y, train_size=0.80, random_state=0)\n",
    "#     # cv：交叉验证 n_points：并行采样的超参组数\n",
    "#     opt = FixedBayesSearchCV(model,cv=5,n_points=2,n_jobs=4,verbose=1,\n",
    "#         search_spaces={\n",
    "#             'output_dim1':Integer(28, 128),\n",
    "#             'num_layer':Integer(3,12),\n",
    "#             'output_dim2':Integer(28, 128)\n",
    "#         },\n",
    "#          fit_params={\n",
    "#                  'eval_set':[(test_x, test_y)],\n",
    "#                  'eval_metric': 'mse',\n",
    "#                  'early_stopping_rounds': 50\n",
    "#                  })\n",
    "#     opt.fit(train_x,train_y)\n",
    "#     print(\"val. score: %s\" % opt.best_score_)\n",
    "#     print(\"test score: %s\" % opt.score(test_x, test_y))\n",
    "#     print(\"Best parameters: \", opt.best_params_)\n",
    "#     print(\"Best estimator:\", opt.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\envs\\python36env\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(input_shape=(10, 1), activation=\"relu\", return_sequences=True, units=128)`\n",
      "  import sys\n",
      "e:\\envs\\python36env\\lib\\site-packages\\ipykernel_launcher.py:11: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(activation=\"tanh\", return_sequences=True, units=128)`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "e:\\envs\\python36env\\lib\\site-packages\\ipykernel_launcher.py:14: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(activation=\"tanh\", units=128)`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "model = create_model(128, 5, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lstm_auto_para_tuning_bayesian(model,data_x,data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "10000/10000 [==============================] - 179s 18ms/step - loss: 1.0698 - mean_squared_error: 1.0698\n",
      "Epoch 2/20\n",
      "10000/10000 [==============================] - 116s 12ms/step - loss: 0.3499 - mean_squared_error: 0.3499\n",
      "Epoch 3/20\n",
      "10000/10000 [==============================] - 116s 12ms/step - loss: 0.1168 - mean_squared_error: 0.1168\n",
      "Epoch 4/20\n",
      "10000/10000 [==============================] - 117s 12ms/step - loss: 0.1380 - mean_squared_error: 0.1380\n",
      "Epoch 5/20\n",
      "10000/10000 [==============================] - 119s 12ms/step - loss: 0.0719 - mean_squared_error: 0.0719\n",
      "Epoch 6/20\n",
      "10000/10000 [==============================] - 103s 10ms/step - loss: 0.0511 - mean_squared_error: 0.0511\n",
      "Epoch 7/20\n",
      "10000/10000 [==============================] - 95s 9ms/step - loss: 0.0594 - mean_squared_error: 0.0594\n",
      "Epoch 8/20\n",
      "10000/10000 [==============================] - 92s 9ms/step - loss: 0.0410 - mean_squared_error: 0.0410\n",
      "Epoch 9/20\n",
      "10000/10000 [==============================] - 90s 9ms/step - loss: 0.0423 - mean_squared_error: 0.0423\n",
      "Epoch 10/20\n",
      "10000/10000 [==============================] - 96s 10ms/step - loss: 0.0386 - mean_squared_error: 0.0386\n",
      "Epoch 11/20\n",
      "10000/10000 [==============================] - 122s 12ms/step - loss: 0.0352 - mean_squared_error: 0.0352\n",
      "Epoch 12/20\n",
      "10000/10000 [==============================] - 115s 12ms/step - loss: 0.0342 - mean_squared_error: 0.0342\n",
      "Epoch 13/20\n",
      "10000/10000 [==============================] - 115s 11ms/step - loss: 0.0312 - mean_squared_error: 0.0312\n",
      "Epoch 14/20\n",
      "10000/10000 [==============================] - 125s 13ms/step - loss: 0.0285 - mean_squared_error: 0.0285\n",
      "Epoch 15/20\n",
      "10000/10000 [==============================] - 162s 16ms/step - loss: 0.0259 - mean_squared_error: 0.0259\n",
      "Epoch 16/20\n",
      "10000/10000 [==============================] - 152s 15ms/step - loss: 0.0223 - mean_squared_error: 0.0223\n",
      "Epoch 17/20\n",
      "10000/10000 [==============================] - 150s 15ms/step - loss: 0.0183 - mean_squared_error: 0.0183\n",
      "Epoch 18/20\n",
      "10000/10000 [==============================] - 141s 14ms/step - loss: 0.0136 - mean_squared_error: 0.0136\n",
      "Epoch 19/20\n",
      "10000/10000 [==============================] - 112s 11ms/step - loss: 0.0085 - mean_squared_error: 0.0085\n",
      "Epoch 20/20\n",
      "10000/10000 [==============================] - 114s 11ms/step - loss: 0.0037 - mean_squared_error: 0.0037\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x279861272e8>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(data_x_train, data_y_train, epochs=20, batch_size=2000, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 14s 7ms/step\n",
      "\n",
      "test loss 0.00031\n",
      "accuracy 0.00031\n"
     ]
    }
   ],
   "source": [
    "# 评估模型,不输出预测结果\n",
    "loss,accuracy = model.evaluate(data_x_test,data_y_test)\n",
    "print('\\ntest loss','{:.5f}'.format(loss))\n",
    "print('accuracy','{:.5f}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(data_x_test,batch_size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_y_test[-10:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_x_test[-10:,0,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = []\n",
    "for i in range(2000):\n",
    "    if data_y_test[:,0][i]>data_x_test[:,0,-1][i]:\n",
    "        t.append(1)\n",
    "    else:\n",
    "        t.append(0)\n",
    "len(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = []\n",
    "for i in range(2000):\n",
    "    if y_pred[:,0][i]>data_x_test[:,0,-1][i]:\n",
    "        p.append(1)\n",
    "    else:\n",
    "        p.append(0)\n",
    "len(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.601"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 0\n",
    "for i in range(2000):\n",
    "    if t[i]==p[i]:\n",
    "        n=n+1\n",
    "n/2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('model.h5')#保存名为model的h5文件到程序所在目录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.predict(data_x_test,batch_size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_pred = [1.08244, 1.0776, 1.08229, 1.08564, 1.08607, 1.08739, 1.08386, 1.09066, 1.09798, 1.0912]\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_pred = np.array(x_pred).reshape(1,10,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.predict(x_pred,batch_size = 1).tolist()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 1)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.2150083],\n",
       "       [1.212196 ],\n",
       "       [1.2092055],\n",
       "       ...,\n",
       "       [1.0982481],\n",
       "       [1.093867 ],\n",
       "       [1.0909857]], dtype=float32)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_t = data_y_test.reshape(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_p = y_pred.reshape(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    " df_test_output = pd.DataFrame(columns=['真实值', '预测值'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_output['真实值'] = y_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_output['预测值'] = y_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>真实值</th>\n",
       "      <th>预测值</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.22287</td>\n",
       "      <td>1.215008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.21822</td>\n",
       "      <td>1.212196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.23848</td>\n",
       "      <td>1.209206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.23980</td>\n",
       "      <td>1.209921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.23972</td>\n",
       "      <td>1.212526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>1.09347</td>\n",
       "      <td>1.107315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>1.09120</td>\n",
       "      <td>1.101921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>1.09798</td>\n",
       "      <td>1.098248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>1.09066</td>\n",
       "      <td>1.093867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>1.08386</td>\n",
       "      <td>1.090986</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          真实值       预测值\n",
       "0     1.22287  1.215008\n",
       "1     1.21822  1.212196\n",
       "2     1.23848  1.209206\n",
       "3     1.23980  1.209921\n",
       "4     1.23972  1.212526\n",
       "...       ...       ...\n",
       "1995  1.09347  1.107315\n",
       "1996  1.09120  1.101921\n",
       "1997  1.09798  1.098248\n",
       "1998  1.09066  1.093867\n",
       "1999  1.08386  1.090986\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_output.to_csv('EURUSD_test_output.csv',encoding='utf_8_sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
